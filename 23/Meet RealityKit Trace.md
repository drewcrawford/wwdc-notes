Discover how you can use RealityKit Trace to improve the performance of your spatial computing apps. Explore performance profiling guidelines for this platform and learn how the RealityKit Trace template can help you optimize rendering for your apps. We'll also provide guidance on profiling various types of content in your app to help pinpoint performance issues.

# rendering

How does it work?

* your app
* render server
* compositor

* shared space
* full space

when multiple apps render sxs, they render into the shared space.  So your app might be affected by other apps (ex render server, etc).

When your app enters the full space, all other visible apps are hidden.  So perf of your app is no longer affected by hidden apps.

[[Go beyond the window with SwiftUI]]

* Profile in isolation for performance issues, system power impact, etc.
* profile along other apps when you expect to work alongside, etc.

# profiling spatial apps

Demo.

Profile demo.  "RealityKit Trace".  Instruments 15.  Real device and a simulator.  To get the most accuraet information, profile a real device.  When profiling against the similar, not all timing information will be accurate because of hardware/software differences, but you can still use for quick iteration.

Frames.  Each frame rendered by device.  Zoom in on these frames to see how long each took to render.  Check how long each stage of the frame takes to render.  What portion of the render pipeline could be causing performance problems.

Target 90fps.  But the OS might not always target 90fps, it might pick based  on content or environment.  Frame has a deadline.  

* early (green)
* just in time (orange)
* late (red)

Quickly find the problematic parts of the trace by looking at color.

Instrument also visualizes average cpu frame time, and gpu frame time.
Check realityKit metrics instrument.  Draws all bottlenecks that it detected.  Generated by looking at comprehensive timing information from the entire pipeline.

Bottlenecks summarized by severity and type.  Dig in further to see exactly what kind of bottleneck we found.

recommendations in the righthand panel.  

REview the system power impact lane, to understand the power limits you need to work within.

Quite a few dropped frames.  use drag to zoom in on problematic areas.  By adjusting the time range, I can check the bottlenecks the metric instrument found during these long-running frames.  

Largest bottleneck was core animation encoding.  Disclosure triangle under 'realitykit metrics' to see core animation.

We colorcode what is a reasonable threshold for these metrics.  Clear that the application is exceeding the recommended threshold for offscreen prepares.  
### SwiftUI View with High Offscreens - 10:50
```swift
private struct Item: View {
    var module: Module

    // The corner radius of the item's hightlight when selected or hovering.
    let cornerRadius = 20.0

    var body: some View {
        NavigationLink(value: module) {
            VStack(alignment: .leading, spacing: 3) {
                Text(module.eyebrow)
                    .font(.titleHeading)
                    .foregroundStyle(.secondary)
                VStack(alignment: .leading, spacing: 7) {
                    Text(module.heading)
                        .font(.largeTitle)
                    Text(module.abstract)
                }
            }
            .padding(.horizontal, 5)
            .padding(.vertical, 20)
        }
        .buttonStyle(.bordered)
        .shadow(radius: 10)
        .buttonBorderShape(.roundedRectangle(radius: cornerRadius))
        .frame(minWidth: 150, maxWidth: 280)
    }
}
```
optimizing CA work
* transparency and blur - very expensive for the system.  use these when they deliver the most impact to the user.
* render passes - how many layers CA has to render individually for the entire image
* offscreen passes.  Render pass that is rendered 'offscreen' not 'to display'.  Requires the rendering pass to pause, and do some work that won't be shown.  However the output is needed to continue the regular rendering pass.  Particularly impactful for spatial apps.
* Spatial apps are always rendering.  Every single frame needs to account for environmental factors such as head movements.  Therefore, static UI must be efficient enough to render at target framerate
	* Shadows
	* Masking
	* Rounded rectangles
	* Visual effects
	* [[Demistify and eliminate hitches in the render phase - 21]]

 Use shadows when they deliver a significant effect for the user.  
GPU work stall - bottleneck type reproted most frequently.  

3D render track.  Basically triangle/vertex counts are outside threshold.  Evaluate the number and quality of assets in the scene.

* check triangles, vertices, and draw calls
* Check statistics with Reality Composer Pro

[[Meet Reality Composer Pro]]

Target for your application to work well by staying in nominal power state.  Always profile with your application in isolation to get most acionable information.

Lower power impact:
* rendering metrics are within expectations
* Check CPU workload
* Check GPU performance states and workload.  Use Metal System Trace to see what work is beign done on GPU to understand what could be optimized.

### EarthEntity Factory - 16:33
```swift
class EarthEntity: Entity {
    static func makeGlobe() -> EarthEntity {
        EarthEntity(earthModel: Entity.makeModel(
            name: "Earth",
            filename: "Globe",
            radius: 0.35,
            color: .blue)
        )
    }

    static func makeCloudyEarth() -> EarthEntity {
        let earthModel = Entity()
        earthModel.name = "Earth"

        Task {
            if let scene = await loadFromRealityComposerPro(
                named: WorldAssets.rootNodeName,
                fromSceneNamed: WorldAssets.sceneName
            ) {
                earthModel.addChild(scene)
            } else {
                fatalError("Unable to load earth model")
            }
        }

        return EarthEntity(earthModel: earthModel)
    }
}
```



### Orbit SwiftUI View Body - 16:53
```swift
struct Orbit: View {
    @EnvironmentObject private var model: ViewModel

    var body: some View {
        Earth(
            world: EarthEntity.makeGlobe(),
            earthConfiguration: model.orbitEarth,
            satelliteConfiguration: [model.orbitSatellite],
            moonConfiguration: model.orbitMoon,

            showSun: true,
            sunAngle: model.orbitSunAngle,

            animateUpdates: true
        )
        .place(
            initialPosition: Point3D([475, -1200.0, -1200.0]),
            useCustomGesture: model.useCustomGesture,
            handOffset: model.customGestureHandOffset,
            isCustomGestureAnimated: model.isCustomGestureAnimated,
            debugCustomGesture: model.debugCustomGesture,
            scale: $model.orbitEarth.scale)
    }
}
```
view body needs to be computed quickly.  Avoid expensive model operations.  Any time the state of the view changes, all those expensive operations need to be recomputed.


### SwiftUI ViewModel - 17:26
```swift
class ViewModel: ObservableObject {
    // MARK: - Navigation
    @Published var navigationPath: [Module] = []
    @Published var titleText: String = ""
    @Published var isTitleFinished: Bool = false
    var finalTitle: String = "Hello World"

    // MARK: - Globe
    @Published var globeEarthEntity: EarthEntity = .makeGlobe()

    @Published var isShowingGlobe: Bool = false
    @Published var globeEarth: EarthEntity.Configuration = .globeEarthDefault
    @Published var globeEarthOffset: SIMD3<Double> = [0, 0, 0]
    @Published var globePanelOffset: SIMD3<Double> = [0, -50, 30]

    @Published var showSatelliteButton: Bool = false
    @Published var isShowingSatellite: Bool = false

    // MARK: - Orbit
    @Published var orbitEarthEntity: EarthEntity = .makeGlobe()

    @Published var useCustomGesture: Bool = true
    @Published var customGestureHandOffset: SIMD3<Float> = [0, 0.21, -0.07]
    @Published var isCustomGestureAnimated: Bool = false
    @Published var debugCustomGesture: Bool = false

    @Published var orbitSatelliteScale: Float = 0.9
    @Published var orbitMoonScale: Float = 0.9
    @Published var orbitTelescopeScale: Float = 0.8
    @Published var orbitSatelliteZOffset: Double = 100
    @Published var orbitMoonZOffset: Double = 100
    @Published var orbitTelescopeZOffset: Double = 100

    @Published var isShowingOrbit: Bool = false
    @Published var orbitImmersionStyle: ImmersionStyle = .mixed
    @Published var orbitEarth: EarthEntity.Configuration = .orbitEarthDefault
    @Published var orbitSatellite: SatelliteEntity.Configuration = .orbitSatelliteDefault
    @Published var orbitMoon: SatelliteEntity.Configuration = .orbitMoonDefault

    @Published var orbitSunAngle: Angle = .degrees(150)
    var orbitSunAngleBinding: Binding<Float> {
        Binding<Float>(
            get: { Float(self.orbitSunAngle.degrees) },
            set: { self.orbitSunAngle = .degrees(Double($0)) }
        )
    }

    // MARK: - Solar System
    @Published var solarEarthEntity: EarthEntity = .makeCloudyEarth()

    @Published var isShowingSolar: Bool = false
    @Published var solarImmersionStyle: ImmersionStyle = .full
    @Published var solarEarth: EarthEntity.Configuration = .solarEarthDefault
    @Published var solarSatellite: SatelliteEntity.Configuration = .solarTelescopeDefault
    @Published var solarMoon: SatelliteEntity.Configuration = .solarMoonDefault

    @Published var solarSunDistance: Double = 700
    @Published var solarSunAngle: Angle = .degrees(280)
    @Published var solarSunSpotIntensity: Float = 10.5
    @Published var solarSunEmissionIntensity: Float = 10.5
    var solarSunPosition: SIMD3<Float> {
        [Float(solarSunDistance * sin(solarSunAngle.radians)),
         0,
         Float(solarSunDistance * cos(solarSunAngle.radians))]
    }
}
```

### SwiftUI Orbit View Body - 17:33
```swift
struct Orbit: View {
    @EnvironmentObject private var model: ViewModel

    var body: some View {
        Earth(
            world: model.globeEarthEntity,
            earthConfiguration: model.orbitEarth,
            satelliteConfiguration: [model.orbitSatellite],
            moonConfiguration: model.orbitMoon,

            showSun: true,
            sunAngle: model.orbitSunAngle,

            animateUpdates: true
        )
        .place(
            initialPosition: Point3D([475, -1200.0, -1200.0]),
            useCustomGesture: model.useCustomGesture,
            handOffset: model.customGestureHandOffset,
            isCustomGestureAnimated: model.isCustomGestureAnimated,
            debugCustomGesture: model.debugCustomGesture,
            scale: $model.orbitEarth.scale)
    }
}
```
* swiftui instruments
* coreanimation instruments
* hangs
[[Analyze hangs with Instruments]]

profile 3d assets
* time profiler for asset loading
* RealityKit metrics for asset rendering
* Check assets using Reality Composer Pro

[[Meet Reality Composer Pro]]

Profile metal content
* Use metal system trace
* check gpu timeline and cpu encoding
* gpu counters and shader timelines
* gpu performance state
[[Discover Metal debugging, profiling, and asset creation tools]]

# Wrap up
* Explore RealityKit trace
* Profile proactively
* see developer docs
[[Optimize app power and performance for spatial computing]]

# Recommendations

# Resources
* https://developer.apple.com/documentation/visionOS/analyzing-the-performance-of-your-visionOS-app
* 