Learn how to speed up machine learning features in your app with the latest Core ML execution engine improvements and find out how aggressive asset caching can help with inference and faster model loads. We'll show you some of the latest options for async prediction and discuss considerations for balancing performance with overall memory usage to help you create a highly responsive app. Discover APIs to help you understand and maximize hardware utilization for your models. For more on optimizing Core ML model usage, check out "Use Core ML Tools for machine learning model compression" from WWDC23.

# Resources
* https://developer.apple.com/documentation/coreml
