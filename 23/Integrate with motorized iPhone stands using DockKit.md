Discover how you can create incredible photo and video experiences in your camera app when integrating with DockKit-compatible motorized stands. We'll show how your app can automatically track subjects in live video across a 360-degree field of view, take direct control of the stand to customize framing, directly control the motors, and provide your own inference model for tracking other objects. Finally, we'll demonstrate how to create a sense of emotion through dynamic device animations. To learn more techniques for image tracking, check out “Detect animal poses in Vision” from WWDC23 and "Classify hand poses and actions with Create ML” from WWDC21.

# Resources
* https://developer.apple.com/documentation/CreateML
* https://developer.apple.com/documentation/DockKit
* https://developer.apple.com/documentation/vision
